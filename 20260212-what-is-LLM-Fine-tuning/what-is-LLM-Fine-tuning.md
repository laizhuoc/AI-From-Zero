# LLM 微调技术科普
![总体概括图](./assets/images/Abstract1.png)
## 一、什么是微调

微调（Fine-tuning）是指在一个已经预训练好的大语言模型基础上，用特定领域或任务的数据继续训练，让模型更好地适应具体需求。

打个比方，预训练模型像是一个读过海量书籍的**通才**，而微调就是让这个通才去某个专业领域进修，变成该领域的**专家**。

## 二、为什么需要微调

预训练模型虽然知识面广，但在具体场景下往往不够精准。比如你想让模型学会用特定的语气回复客户、掌握公司内部的专业术语、或者更好地完成某类特定任务（如代码生成、医疗问答），直接用通用模型效果不理想。

微调可以让模型学会这些特定的模式和知识，同时**成本远低于从头训练一个模型**。

## 三、主流微调方法

- **全参数微调（Full Fine-tuning）**：对模型所有参数进行更新。效果最好但成本最高，需要大量显存和计算资源，对于动辄几十亿参数的大模型来说门槛很高。

- **LoRA（Low-Rank Adaptation）**：在原模型旁边插入小规模的可训练矩阵，只训练这些新增参数，原模型参数冻结不变。显存需求大幅降低，训练速度快，是目前最流行的方法之一。

- **QLoRA**：在 LoRA 基础上结合量化技术，把原模型用 4-bit 量化存储，进一步降低显存占用，让普通消费级显卡也能微调大模型。

- **P-Tuning / Prefix Tuning**：不改动模型参数，而是在输入前面加上一段可学习的"软提示"（soft prompt），通过优化这段提示来引导模型行为。参数量极小，但效果在某些场景下不如 LoRA。

- **Adapter**：在 Transformer 的每一层中插入小型适配器模块，只训练这些模块。思路和 LoRA 类似，但结构不同。

## 四、微调的基本流程

1. **选择基础模型**：使用预训练好的通用语言模型（如 Qwen、LLaMA 等）作为起点
2. **准备领域数据**：收集与目标领域相关的标注数据集
3. **调整超参数（Hyperparameters）**：设置合适的学习率、训练轮次等参数（通常比预训练时更小，这些都是超参数）
4. **领域适应训练**：在保持原有参数的基础上，用领域数据继续训练模型
5. **评估验证**：通过领域特定的评估指标检验微调效果
6. **迭代优化**：重复上述过程来获得更好的结果直到满意

## 五、微调 vs 其他技术的对比

### 与 RAG（检索增强生成）对比

RAG 是让模型在回答时检索外部知识库，不改变模型本身；微调是改变模型参数。RAG 适合需要**实时更新知识**的场景，微调适合需要**改变模型行为模式**的场景，两者也可以结合使用。

### 与 Prompt Engineering 对比

提示工程是通过设计输入提示词来引导模型，不需要训练；微调需要训练但效果更稳定。简单任务用提示工程即可，复杂或高频任务适合微调。

## 六、实际应用场景

- **垂直领域适配**：最常见的场景，比如法律、医疗、金融等专业领域的问答系统
- **风格定制**：让模型学会特定的回复风格、语气或人设
- **指令遵循优化**：让模型更好地理解和执行特定格式的指令
- **安全对齐**：通过微调减少模型输出有害内容的倾向